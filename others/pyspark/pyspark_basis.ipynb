{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# import findspark\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# findspark.init()pip\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "# import findspark\n",
    "# findspark.init()pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/firaterman/Documents/git_workspace/FERMAN/pyspark'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/25 17:29:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "#Define the sparksession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"pp\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# import pfile \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheader\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcsv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/ferman/Documents/data/NameAge.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m df\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "# import pfile \n",
    "df = spark.read.option(\"header\",\"true\").csv(\"/home/ferman/Documents/data/NameAge.csv\")\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mprintSchema()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.select(\"name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|  name|age|\n",
      "+------+---+\n",
      "| prash| 35|\n",
      "|Serhat| 28|\n",
      "| roxto| 45|\n",
      "| Malim| 25|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select([\"name\",\"age\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.select([\"name\",\"age\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('name', 'string'), ('age', 'string')]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, name: string, age: string]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if we have a dataframe and format of columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+----------------+\n",
      "|summary| name|             age|\n",
      "+-------+-----+----------------+\n",
      "|  count|    4|               4|\n",
      "|   mean| null|           33.25|\n",
      "| stddev| null|8.88350531415762|\n",
      "|    min|Malim|              25|\n",
      "|    max|roxto|              45|\n",
      "+-------+-----+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+---------+\n",
      "|  name|age|add5years|\n",
      "+------+---+---------+\n",
      "| prash| 35|     37.0|\n",
      "|Serhat| 28|     30.0|\n",
      "| roxto| 45|     47.0|\n",
      "| Malim| 25|     27.0|\n",
      "+------+---+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"add5years\",df['age']+2)\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|  name|age|\n",
      "+------+---+\n",
      "| prash| 35|\n",
      "|Serhat| 28|\n",
      "| roxto| 45|\n",
      "| Malim| 25|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop columns\n",
    "df = df.drop(\"add5years\")\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|surname|age|\n",
      "+-------+---+\n",
      "|  prash| 35|\n",
      "| Serhat| 28|\n",
      "|  roxto| 45|\n",
      "|  Malim| 25|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Rename columns\n",
    "df = df.withColumnRenamed(\"name\",\"surname\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MISSING VALUES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+-----+\n",
      "|  name| age| city|\n",
      "+------+----+-----+\n",
      "| prash|  35|Paris|\n",
      "|Serhat|  28| null|\n",
      "|  null|  45| Amed|\n",
      "| Malim|  25|kyoto|\n",
      "| Malim|null|tokyo|\n",
      "+------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import a new dataset\n",
    "dfCity = spark.read.csv(\"/home/ferman/Documents/data/NameAgeCity.csv\", header=True, inferSchema=True)\n",
    "dfCity.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----+\n",
      "| name|age| city|\n",
      "+-----+---+-----+\n",
      "|prash| 35|Paris|\n",
      "|Malim| 25|kyoto|\n",
      "+-----+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop all columns conaining null values\n",
    "dfCity.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----+\n",
      "| name|age| city|\n",
      "+-----+---+-----+\n",
      "|prash| 35|Paris|\n",
      "|Malim| 25|kyoto|\n",
      "+-----+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop only the column with any\n",
    "dfCity.na.drop(how=\"any\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+-----+\n",
      "|  name| age| city|\n",
      "+------+----+-----+\n",
      "| prash|  35|Paris|\n",
      "|Serhat|  28| null|\n",
      "|  null|  45| Amed|\n",
      "| Malim|  25|kyoto|\n",
      "| Malim|null|tokyo|\n",
      "+------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop only those with whole raw containing null values\n",
    "dfCity.na.drop(how=\"all\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----+\n",
      "| name|age| city|\n",
      "+-----+---+-----+\n",
      "|prash| 35|Paris|\n",
      "|Malim| 25|kyoto|\n",
      "+-----+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop only the column with any and treshhold means at least \"x\" value of the treshold is non missing values\n",
    "dfCity.na.drop(how=\"any\",thresh=3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+-----+\n",
      "|  name|age| city|\n",
      "+------+---+-----+\n",
      "| prash| 35|Paris|\n",
      "|Serhat| 28| null|\n",
      "|  null| 45| Amed|\n",
      "| Malim| 25|kyoto|\n",
      "+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop missing values only for this column so it drop whole row\n",
    "dfCity.na.drop(how=\"any\",subset=[\"age\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----+------------+\n",
      "|        name| age|        city|\n",
      "+------------+----+------------+\n",
      "|       prash|  35|       Paris|\n",
      "|      Serhat|  28|MissingValue|\n",
      "|MissingValue|  45|        Amed|\n",
      "|       Malim|  25|       kyoto|\n",
      "|       Malim|null|       tokyo|\n",
      "+------------+----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filling the missing value\n",
    "\n",
    "dfCity.na.fill(\"MissingValue\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+------------+\n",
      "|  name| age|        city|\n",
      "+------+----+------------+\n",
      "| prash|  35|       Paris|\n",
      "|Serhat|  28|MissingValue|\n",
      "|  null|  45|        Amed|\n",
      "| Malim|  25|       kyoto|\n",
      "| Malim|null|       tokyo|\n",
      "+------+----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# only for specific columns\n",
    "dfCity.na.fill(\"MissingValue\",[\"age\",\"city\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputer replace with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+-----+------+\n",
      "|  name| age| city|salary|\n",
      "+------+----+-----+------+\n",
      "| prash|  35|Paris|  2000|\n",
      "|Serhat|null| null|  1000|\n",
      "|  null|  45| Amed|  null|\n",
      "| Malim|  25|kyoto| 20000|\n",
      "| halwo|null|tokyo|  null|\n",
      "+------+----+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# add inferSchema to consider number as integer\n",
    "dfSalary = spark.read.csv(\"/home/ferman/Documents/data/NameAgeCitySalary.csv\", header = True, inferSchema=True)\n",
    "dfSalary.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repalce non values by mean/average/etc...\n",
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "targetedColumns = ['age','salary']\n",
    "strategy= \"median\" #median or else\n",
    "imputer = Imputer (\n",
    "    inputCols = targetedColumns,\n",
    "    outputCols= ['{}_imputer'.format(c) for c in targetedColumns]\n",
    "\n",
    ").setStrategy(strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+-----+------+-----------+--------------+\n",
      "|  name| age| city|salary|age_imputer|salary_imputer|\n",
      "+------+----+-----+------+-----------+--------------+\n",
      "| prash|  35|Paris|  2000|         35|          2000|\n",
      "|Serhat|null| null|  1000|         35|          1000|\n",
      "|  null|  45| Amed|  null|         45|          2000|\n",
      "| Malim|  25|kyoto| 20000|         25|         20000|\n",
      "| halwo|null|tokyo|  null|         35|          2000|\n",
      "+------+----+-----+------+-----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfWithImputer = imputer.fit(dfSalary).transform(dfSalary)\n",
    "dfWithImputer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|salary|age|\n",
      "+------+---+\n",
      "| 20000| 25|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filter\n",
    "dfWithImputer.filter(\"salary>2000\").select([\"salary\",\"age\"]).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----+------+-----------+--------------+\n",
      "| name|age| city|salary|age_imputer|salary_imputer|\n",
      "+-----+---+-----+------+-----------+--------------+\n",
      "|Malim| 25|kyoto| 20000|         25|         20000|\n",
      "+-----+---+-----+------+-----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfWithImputer.filter(\"salary>2000\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### another way to filter : BEST WAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----+------+-----------+--------------+\n",
      "| name|age| city|salary|age_imputer|salary_imputer|\n",
      "+-----+---+-----+------+-----------+--------------+\n",
      "|Malim| 25|kyoto| 20000|         25|         20000|\n",
      "+-----+---+-----+------+-----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfWithImputer.filter(dfWithImputer[\"salary\"]>3000).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----+------+-----------+--------------+\n",
      "| name|age| city|salary|age_imputer|salary_imputer|\n",
      "+-----+---+-----+------+-----------+--------------+\n",
      "|Malim| 25|kyoto| 20000|         25|         20000|\n",
      "+-----+---+-----+------+-----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfWithImputer.filter((dfWithImputer[\"salary\"]>3000) & (dfWithImputer['age']>10)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|age|\n",
      "+---+\n",
      "| 25|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfWithImputer.filter((dfWithImputer[\"salary\"]>3000) & (dfWithImputer['age']>10)).select(\"age\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfWithImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26496b33b38e8efc2a4cb759e0fb8cb09939f267f5e6b182cad057a79f8d9e87"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('venv_python_playground': pyenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
