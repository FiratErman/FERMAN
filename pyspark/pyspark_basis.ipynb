{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pandas as pd \n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ferman/Documents/FERMAN/pyspark'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/21 09:41:04 WARN Utils: Your hostname, Ferman resolves to a loopback address: 127.0.1.1; using 192.168.1.50 instead (on interface enp7s0)\n",
      "21/11/21 09:41:04 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark/jars/spark-unsafe_2.13-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/11/21 09:41:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "#Define the sparksession\n",
    "spark = SparkSession.builder.appName(\"pysparkBasis\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|  name|age|\n",
      "+------+---+\n",
      "| prash| 35|\n",
      "|Serhat| 28|\n",
      "| roxto| 45|\n",
      "| Malim| 25|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import pfile \n",
    "df = spark.read.option(\"header\",\"true\").csv(\"/home/ferman/Documents/data/NameAge.csv\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|  name|\n",
      "+------+\n",
      "| prash|\n",
      "|Serhat|\n",
      "| roxto|\n",
      "| Malim|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|  name|age|\n",
      "+------+---+\n",
      "| prash| 35|\n",
      "|Serhat| 28|\n",
      "| roxto| 45|\n",
      "| Malim| 25|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select([\"name\",\"age\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.select([\"name\",\"age\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('name', 'string'), ('age', 'string')]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, name: string, age: string]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if we have a dataframe and format of columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+----------------+\n",
      "|summary| name|             age|\n",
      "+-------+-----+----------------+\n",
      "|  count|    4|               4|\n",
      "|   mean| null|           33.25|\n",
      "| stddev| null|8.88350531415762|\n",
      "|    min|Malim|              25|\n",
      "|    max|roxto|              45|\n",
      "+-------+-----+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+---------+\n",
      "|  name|age|add5years|\n",
      "+------+---+---------+\n",
      "| prash| 35|     37.0|\n",
      "|Serhat| 28|     30.0|\n",
      "| roxto| 45|     47.0|\n",
      "| Malim| 25|     27.0|\n",
      "+------+---+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"add5years\",df['age']+2)\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|  name|age|\n",
      "+------+---+\n",
      "| prash| 35|\n",
      "|Serhat| 28|\n",
      "| roxto| 45|\n",
      "| Malim| 25|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop columns\n",
    "df = df.drop(\"add5years\")\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|surname|age|\n",
      "+-------+---+\n",
      "|  prash| 35|\n",
      "| Serhat| 28|\n",
      "|  roxto| 45|\n",
      "|  Malim| 25|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Rename columns\n",
    "df = df.withColumnRenamed(\"name\",\"surname\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MISSING VALUES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+-----+\n",
      "|  name| age| city|\n",
      "+------+----+-----+\n",
      "| prash|  35|Paris|\n",
      "|Serhat|  28| null|\n",
      "|  null|  45| Amed|\n",
      "| Malim|  25|kyoto|\n",
      "| Malim|null|tokyo|\n",
      "+------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import a new dataset\n",
    "dfCity = spark.read.csv(\"/home/ferman/Documents/data/NameAgeCity.csv\", header=True, inferSchema=True)\n",
    "dfCity.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----+\n",
      "| name|age| city|\n",
      "+-----+---+-----+\n",
      "|prash| 35|Paris|\n",
      "|Malim| 25|kyoto|\n",
      "+-----+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop all columns conaining null values\n",
    "dfCity.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----+\n",
      "| name|age| city|\n",
      "+-----+---+-----+\n",
      "|prash| 35|Paris|\n",
      "|Malim| 25|kyoto|\n",
      "+-----+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop only the column with any\n",
    "dfCity.na.drop(how=\"any\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+-----+\n",
      "|  name| age| city|\n",
      "+------+----+-----+\n",
      "| prash|  35|Paris|\n",
      "|Serhat|  28| null|\n",
      "|  null|  45| Amed|\n",
      "| Malim|  25|kyoto|\n",
      "| Malim|null|tokyo|\n",
      "+------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop only those with whole raw containing null values\n",
    "dfCity.na.drop(how=\"all\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----+\n",
      "| name|age| city|\n",
      "+-----+---+-----+\n",
      "|prash| 35|Paris|\n",
      "|Malim| 25|kyoto|\n",
      "+-----+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop only the column with any and treshhold means at least \"x\" value of the treshold is non missing values\n",
    "dfCity.na.drop(how=\"any\",thresh=3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+-----+\n",
      "|  name|age| city|\n",
      "+------+---+-----+\n",
      "| prash| 35|Paris|\n",
      "|Serhat| 28| null|\n",
      "|  null| 45| Amed|\n",
      "| Malim| 25|kyoto|\n",
      "+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop missing values only for this column so it drop whole row\n",
    "dfCity.na.drop(how=\"any\",subset=[\"age\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----+------------+\n",
      "|        name| age|        city|\n",
      "+------------+----+------------+\n",
      "|       prash|  35|       Paris|\n",
      "|      Serhat|  28|MissingValue|\n",
      "|MissingValue|  45|        Amed|\n",
      "|       Malim|  25|       kyoto|\n",
      "|       Malim|null|       tokyo|\n",
      "+------------+----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filling the missing value\n",
    "\n",
    "dfCity.na.fill(\"MissingValue\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+------------+\n",
      "|  name| age|        city|\n",
      "+------+----+------------+\n",
      "| prash|  35|       Paris|\n",
      "|Serhat|  28|MissingValue|\n",
      "|  null|  45|        Amed|\n",
      "| Malim|  25|       kyoto|\n",
      "| Malim|null|       tokyo|\n",
      "+------+----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# only for specific columns\n",
    "dfCity.na.fill(\"MissingValue\",[\"age\",\"city\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputer replace with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+-----+------+\n",
      "|  name| age| city|salary|\n",
      "+------+----+-----+------+\n",
      "| prash|  35|Paris|  2000|\n",
      "|Serhat|null| null|  1000|\n",
      "|  null|  45| Amed|  null|\n",
      "| Malim|  25|kyoto| 20000|\n",
      "| halwo|null|tokyo|  null|\n",
      "+------+----+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# add inferSchema to consider number as integer\n",
    "dfSalary = spark.read.csv(\"/home/ferman/Documents/data/NameAgeCitySalary.csv\", header = True, inferSchema=True)\n",
    "dfSalary.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repalce non values by mean/average/etc...\n",
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "targetedColumns = ['age','salary']\n",
    "strategy= \"median\" #median or else\n",
    "imputer = Imputer (\n",
    "    inputCols = targetedColumns,\n",
    "    outputCols= ['{}_imputer'.format(c) for c in targetedColumns]\n",
    "\n",
    ").setStrategy(strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+-----+------+-----------+--------------+\n",
      "|  name| age| city|salary|age_imputer|salary_imputer|\n",
      "+------+----+-----+------+-----------+--------------+\n",
      "| prash|  35|Paris|  2000|         35|          2000|\n",
      "|Serhat|null| null|  1000|         35|          1000|\n",
      "|  null|  45| Amed|  null|         45|          2000|\n",
      "| Malim|  25|kyoto| 20000|         25|         20000|\n",
      "| halwo|null|tokyo|  null|         35|          2000|\n",
      "+------+----+-----+------+-----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfWithImputer = imputer.fit(dfSalary).transform(dfSalary)\n",
    "dfWithImputer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|salary|age|\n",
      "+------+---+\n",
      "| 20000| 25|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filter\n",
    "dfWithImputer.filter(\"salary>2000\").select([\"salary\",\"age\"]).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----+------+-----------+--------------+\n",
      "| name|age| city|salary|age_imputer|salary_imputer|\n",
      "+-----+---+-----+------+-----------+--------------+\n",
      "|Malim| 25|kyoto| 20000|         25|         20000|\n",
      "+-----+---+-----+------+-----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfWithImputer.filter(\"salary>2000\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### another way to filter : BEST WAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----+------+-----------+--------------+\n",
      "| name|age| city|salary|age_imputer|salary_imputer|\n",
      "+-----+---+-----+------+-----------+--------------+\n",
      "|Malim| 25|kyoto| 20000|         25|         20000|\n",
      "+-----+---+-----+------+-----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfWithImputer.filter(dfWithImputer[\"salary\"]>3000).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----+------+-----------+--------------+\n",
      "| name|age| city|salary|age_imputer|salary_imputer|\n",
      "+-----+---+-----+------+-----------+--------------+\n",
      "|Malim| 25|kyoto| 20000|         25|         20000|\n",
      "+-----+---+-----+------+-----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfWithImputer.filter((dfWithImputer[\"salary\"]>3000) & (dfWithImputer['age']>10)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|age|\n",
      "+---+\n",
      "| 25|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfWithImputer.filter((dfWithImputer[\"salary\"]>3000) & (dfWithImputer['age']>10)).select(\"age\").show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
